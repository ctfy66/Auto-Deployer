"""å¹¶è¡Œæµ‹è¯•è¿è¡Œå™¨ - ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œæ‰§è¡Œæµ‹è¯•"""
import logging
import sys
from concurrent.futures import ProcessPoolExecutor, as_completed, Future
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from auto_deployer.config import AppConfig
from .test_task import TestTask
from .test_projects import TestProject
from .enhanced_metrics import EnhancedProjectMetrics, SystemInfoCollector, collect_llm_config
from .test_executor import execute_test_task

logger = logging.getLogger(__name__)


class ParallelTestRunner:
    """å¹¶è¡Œæµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(
        self,
        config: AppConfig,
        max_workers: int = 3,
        retry_on_failure: bool = True,
        retry_max_attempts: int = 1,
        timeout_per_project: int = 30,
        log_dir: Path = Path("tests/results")
    ):
        """
        åˆå§‹åŒ–å¹¶è¡Œæµ‹è¯•è¿è¡Œå™¨
        
        Args:
            config: Auto-Deployeré…ç½®
            max_workers: æœ€å¤§å¹¶è¡Œworkeræ•°ï¼ˆé»˜è®¤3ï¼‰
            retry_on_failure: æ˜¯å¦åœ¨å¤±è´¥æ—¶é‡è¯•ï¼ˆé»˜è®¤Trueï¼‰
            retry_max_attempts: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤1ï¼Œå³æœ€å¤šå°è¯•2æ¬¡ï¼‰
            timeout_per_project: å•ä¸ªé¡¹ç›®è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼Œé»˜è®¤30ï¼‰
            log_dir: æ—¥å¿—ç›®å½•
        """
        self.config = config
        self.max_workers = max_workers
        self.retry_on_failure = retry_on_failure
        self.retry_max_attempts = retry_max_attempts + 1  # è½¬æ¢ä¸ºæ€»å°è¯•æ¬¡æ•°
        self.timeout_per_project = timeout_per_project
        self.log_dir = Path(log_dir)
        
        logger.info(f"ðŸš€ åˆå§‹åŒ–å¹¶è¡Œæµ‹è¯•è¿è¡Œå™¨")
        logger.info(f"   å¹¶è¡Œåº¦: {self.max_workers} workers")
        logger.info(f"   é‡è¯•ç­–ç•¥: {'å¯ç”¨' if self.retry_on_failure else 'ç¦ç”¨'}")
        if self.retry_on_failure:
            logger.info(f"   æœ€å¤§é‡è¯•æ¬¡æ•°: {retry_max_attempts}")
    
    def run_tests(
        self,
        projects: List[TestProject],
        env_config: Dict[str, Any],
        local_mode: bool = True
    ) -> List[EnhancedProjectMetrics]:
        """
        å¹¶è¡Œè¿è¡Œæ‰€æœ‰æµ‹è¯•
        
        Args:
            projects: æµ‹è¯•é¡¹ç›®åˆ—è¡¨
            env_config: çŽ¯å¢ƒé…ç½®
            local_mode: æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å¼
            
        Returns:
            å¢žå¼ºçš„é¡¹ç›®æŒ‡æ ‡åˆ—è¡¨
        """
        if not projects:
            logger.warning("âš ï¸  æ²¡æœ‰é¡¹ç›®éœ€è¦æµ‹è¯•")
            return []
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ðŸ“‹ å‡†å¤‡æµ‹è¯• {len(projects)} ä¸ªé¡¹ç›®")
        logger.info(f"{'='*60}\n")
        
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        tasks = self._create_tasks(projects, env_config, local_mode)
        
        # å¹¶è¡Œæ‰§è¡Œ
        results = self._execute_parallel(tasks)
        
        logger.info(f"\n{'='*60}")
        logger.info(f"âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        logger.info(f"{'='*60}\n")
        
        return results
    
    def _create_tasks(
        self,
        projects: List[TestProject],
        env_config: Dict[str, Any],
        local_mode: bool
    ) -> List[TestTask]:
        """
        ä»Žé¡¹ç›®åˆ—è¡¨åˆ›å»ºæµ‹è¯•ä»»åŠ¡
        
        Args:
            projects: é¡¹ç›®åˆ—è¡¨
            env_config: çŽ¯å¢ƒé…ç½®
            local_mode: æœ¬åœ°æ¨¡å¼
            
        Returns:
            ä»»åŠ¡åˆ—è¡¨
        """
        tasks = []
        for project in projects:
            task = TestTask(
                project=project,
                env_config=env_config,
                local_mode=local_mode,
                attempt=1,
                max_attempts=self.retry_max_attempts if self.retry_on_failure else 1
            )
            tasks.append(task)
        
        return tasks
    
    def _execute_parallel(
        self,
        tasks: List[TestTask]
    ) -> List[EnhancedProjectMetrics]:
        """
        å¹¶è¡Œæ‰§è¡Œä»»åŠ¡
        
        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨
            
        Returns:
            ç»“æžœåˆ—è¡¨
        """
        total_tasks = len(tasks)
        results: List[EnhancedProjectMetrics] = []
        completed_count = 0
        
        # åˆ›å»ºè¿›ç¨‹æ± 
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task: Dict[Future, TestTask] = {}
            
            for i, task in enumerate(tasks):
                future = executor.submit(
                    execute_test_task,
                    task=task,
                    config=self.config,
                    worker_id=(i % self.max_workers) + 1,
                    log_dir=self.log_dir
                )
                future_to_task[future] = task
            
            # ä½¿ç”¨ as_completed å®žæ—¶èŽ·å–å®Œæˆçš„ä»»åŠ¡
            try:
                for future in as_completed(
                    future_to_task, 
                    timeout=self.timeout_per_project * 60 * total_tasks
                ):
                    task = future_to_task[future]
                    completed_count += 1
                    
                    try:
                        result = future.result(timeout=self.timeout_per_project * 60)
                        results.append(result)
                        
                        # æ‰“å°è¿›åº¦
                        self._print_progress(completed_count, total_tasks, result)
                        
                    except Exception as e:
                        logger.error(
                            f"[{task.project.name}] âŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}",
                            exc_info=True
                        )
                        
                        # åˆ›å»ºå¤±è´¥ç»“æžœ
                        from .metrics_collector import ProjectMetrics
                        from .enhanced_metrics import enhance_metrics
                        
                        base_metrics = ProjectMetrics(
                            project_name=task.project.name,
                            project_difficulty=task.project.difficulty,
                            success=False,
                            final_status="error",
                            deployment_time_seconds=0.0,
                            total_iterations=0,
                            total_commands=0,
                            llm_call_count=0,
                            user_interactions=0,
                            error_recovery_count=0,
                            strategy_used="unknown",
                            expected_strategy=task.project.expected_strategy,
                            strategy_correct=None,
                            verification_passed=False,
                            verification_details=[],
                            error=str(e)
                        )
                        
                        enhanced = enhance_metrics(
                            base_metrics=base_metrics,
                            repo_url=task.project.repo_url,
                            system_info=SystemInfoCollector.collect_system_info(),
                            llm_config=collect_llm_config(self.config),
                            retry_info=None,
                            test_start_time=datetime.now(),
                            test_end_time=datetime.now(),
                            worker_id=None,
                            task_id=task.task_id
                        )
                        
                        results.append(enhanced)
                        self._print_progress(completed_count, total_tasks, enhanced)
            
            except KeyboardInterrupt:
                logger.warning("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
                executor.shutdown(wait=False, cancel_futures=True)
                raise
        
        return results
    
    def _print_progress(
        self,
        completed: int,
        total: int,
        result: EnhancedProjectMetrics
    ):
        """
        æ‰“å°æµ‹è¯•è¿›åº¦
        
        Args:
            completed: å·²å®Œæˆæ•°é‡
            total: æ€»æ•°é‡
            result: æµ‹è¯•ç»“æžœ
        """
        status_icon = "âœ…" if result.success else "âŒ"
        
        # åŸºæœ¬ä¿¡æ¯
        info_parts = [
            f"[{completed}/{total}]",
            f"{status_icon}",
            f"{result.project_name}:"
        ]
        
        # è¯¦ç»†ä¿¡æ¯
        details = []
        if result.success:
            details.append(f"æˆåŠŸ")
        else:
            details.append(f"å¤±è´¥")
        
        details.append(f"{result.deployment_time_seconds:.1f}s")
        details.append(f"{result.total_iterations} è¿­ä»£")
        
        # é‡è¯•ä¿¡æ¯
        if result.retry_info and result.retry_info.total_attempts > 1:
            details.append(
                f"ðŸ”„ é‡è¯• {result.retry_info.failed_attempts}æ¬¡"
            )
        
        # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æžœå¤±è´¥ï¼‰
        if not result.success and result.error:
            # åªæ˜¾ç¤ºé”™è¯¯çš„å‰50ä¸ªå­—ç¬¦
            error_preview = result.error[:50]
            if len(result.error) > 50:
                error_preview += "..."
            details.append(f"({error_preview})")
        
        info_parts.append(", ".join(details))
        
        logger.info(" ".join(info_parts))

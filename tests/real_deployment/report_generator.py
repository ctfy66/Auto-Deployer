"""æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨ - ç”ŸæˆJSONå’ŒMarkdownæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

from .metrics_collector import ProjectMetrics


class ReportGenerator:
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: Path = Path("tests/results/reports")):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            output_dir: æŠ¥å‘Šè¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def generate_json_report(
        self, 
        results: List[ProjectMetrics], 
        summary: Dict[str, Any],
        config: Dict[str, Any]
    ) -> Path:
        """
        ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Š
        
        Args:
            results: é¡¹ç›®æŒ‡æ ‡åˆ—è¡¨
            summary: èšåˆæ‘˜è¦
            config: æµ‹è¯•é…ç½®
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.output_dir / f"test_report_{timestamp}.json"
        
        report_data = {
            "timestamp": datetime.now().isoformat(),
            "config": config,
            "summary": summary,
            "results": [r.to_dict() for r in results]
        }
        
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        return report_file
    
    def generate_markdown_report(
        self, 
        results: List[ProjectMetrics], 
        summary: Dict[str, Any]
    ) -> Path:
        """
        ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š
        
        Args:
            results: é¡¹ç›®æŒ‡æ ‡åˆ—è¡¨
            summary: èšåˆæ‘˜è¦
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.output_dir / f"test_report_{timestamp}.md"
        
        lines = []
        
        # æ ‡é¢˜
        lines.append("# Auto-Deployer çœŸå®éƒ¨ç½²æµ‹è¯•æŠ¥å‘Š")
        lines.append("")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        
        # æ‘˜è¦
        lines.append("## ğŸ“Š æµ‹è¯•æ‘˜è¦")
        lines.append("")
        lines.append(f"- **æ€»é¡¹ç›®æ•°**: {summary['total_projects']}")
        lines.append(f"- **æˆåŠŸ**: {summary['successful']} âœ…")
        lines.append(f"- **å¤±è´¥**: {summary['failed']} âŒ")
        lines.append(f"- **æˆåŠŸç‡**: {summary['success_rate']:.1f}%")
        lines.append("")
        
        # æŒ‰éš¾åº¦åˆ†ç±»
        if summary.get("by_difficulty"):
            lines.append("### æŒ‰éš¾åº¦åˆ†ç±»")
            lines.append("")
            lines.append("| éš¾åº¦ | æˆåŠŸ | æ€»æ•° | æˆåŠŸç‡ |")
            lines.append("|------|------|------|--------|")
            for diff, stats in summary["by_difficulty"].items():
                lines.append(
                    f"| {diff} | {stats['success']} | {stats['total']} | "
                    f"{stats['success_rate']:.1f}% |"
                )
            lines.append("")
        
        # å¹³å‡æŒ‡æ ‡
        if summary.get("average_metrics"):
            lines.append("### å¹³å‡æŒ‡æ ‡ï¼ˆä»…æˆåŠŸé¡¹ç›®ï¼‰")
            lines.append("")
            avg = summary["average_metrics"]
            lines.append(f"- **éƒ¨ç½²æ—¶é—´**: {avg['deployment_time_seconds']:.1f}ç§’")
            lines.append(f"- **è¿­ä»£æ¬¡æ•°**: {avg['iterations']:.1f}")
            lines.append(f"- **å‘½ä»¤æ•°**: {avg['commands']:.1f}")
            lines.append(f"- **LLMè°ƒç”¨**: {avg['llm_calls']:.1f}")
            lines.append(f"- **ç”¨æˆ·äº¤äº’**: {avg['user_interactions']:.1f}")
            lines.append(f"- **é”™è¯¯æ¢å¤**: {avg['error_recoveries']:.1f}")
            lines.append("")
        
        # ç­–ç•¥å‡†ç¡®ç‡
        if "strategy_accuracy" in summary:
            lines.append(f"### ç­–ç•¥é€‰æ‹©å‡†ç¡®ç‡: {summary['strategy_accuracy']:.1f}%")
            lines.append("")
        
        # éªŒè¯é€šè¿‡ç‡
        if "verification_rate" in summary:
            lines.append(f"### éƒ¨ç½²éªŒè¯é€šè¿‡ç‡: {summary['verification_rate']:.1f}%")
            lines.append("")
        
        # è¯¦ç»†ç»“æœ
        lines.append("## ğŸ“‹ è¯¦ç»†ç»“æœ")
        lines.append("")
        
        for result in results:
            status_emoji = "âœ…" if result.success else "âŒ"
            lines.append(f"### {status_emoji} {result.project_name}")
            lines.append("")
            lines.append(f"- **éš¾åº¦**: {result.project_difficulty}")
            lines.append(f"- **çŠ¶æ€**: {result.final_status}")
            lines.append(f"- **éƒ¨ç½²æ—¶é—´**: {result.deployment_time_seconds:.1f}ç§’")
            lines.append(f"- **è¿­ä»£æ¬¡æ•°**: {result.total_iterations}")
            lines.append(f"- **å‘½ä»¤æ•°**: {result.total_commands}")
            lines.append(f"- **ç­–ç•¥**: {result.strategy_used} (æœŸæœ›: {result.expected_strategy})")
            
            if result.strategy_correct is not None:
                strategy_emoji = "âœ…" if result.strategy_correct else "âŒ"
                lines.append(f"- **ç­–ç•¥æ­£ç¡®**: {strategy_emoji}")
            
            lines.append(f"- **éªŒè¯é€šè¿‡**: {'âœ…' if result.verification_passed else 'âŒ'}")
            
            if result.user_interactions > 0:
                lines.append(f"- **ç”¨æˆ·äº¤äº’**: {result.user_interactions}æ¬¡")
            
            if result.error_recovery_count > 0:
                lines.append(f"- **é”™è¯¯æ¢å¤**: {result.error_recovery_count}æ¬¡")
            
            if result.error:
                lines.append(f"- **é”™è¯¯**: {result.error}")
            
            if result.log_file:
                lines.append(f"- **æ—¥å¿—æ–‡ä»¶**: `{result.log_file}`")
            
            lines.append("")
        
        # å†™å…¥æ–‡ä»¶
        with open(report_file, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        
        return report_file
    
    def print_summary(self, summary: Dict[str, Any]) -> None:
        """
        åœ¨æ§åˆ¶å°æ‰“å°æ‘˜è¦
        
        Args:
            summary: èšåˆæ‘˜è¦
        """
        print(f"\n{'='*60}")
        print("ğŸ“Š æµ‹è¯•æŠ¥å‘Š")
        print(f"{'='*60}")
        print(f"æ€»é¡¹ç›®æ•°: {summary['total_projects']}")
        print(f"æˆåŠŸ: {summary['successful']} âœ…")
        print(f"å¤±è´¥: {summary['failed']} âŒ")
        print(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print()
        
        # æŒ‰éš¾åº¦åˆ†ç±»
        if summary.get("by_difficulty"):
            print("æŒ‰éš¾åº¦åˆ†ç±»:")
            for diff, stats in summary["by_difficulty"].items():
                print(
                    f"  {diff}: {stats['success']}/{stats['total']} "
                    f"({stats['success_rate']:.1f}%)"
                )
            print()
        
        # å¹³å‡æŒ‡æ ‡
        if summary.get("average_metrics"):
            print("å¹³å‡æŒ‡æ ‡ï¼ˆä»…æˆåŠŸé¡¹ç›®ï¼‰:")
            avg = summary["average_metrics"]
            print(f"  éƒ¨ç½²æ—¶é—´: {avg['deployment_time_seconds']:.1f}ç§’")
            print(f"  è¿­ä»£æ¬¡æ•°: {avg['iterations']:.1f}")
            print(f"  å‘½ä»¤æ•°: {avg['commands']:.1f}")
            print(f"  LLMè°ƒç”¨: {avg['llm_calls']:.1f}")
            if avg.get('user_interactions', 0) > 0:
                print(f"  ç”¨æˆ·äº¤äº’: {avg['user_interactions']:.1f}")
            if avg.get('error_recoveries', 0) > 0:
                print(f"  é”™è¯¯æ¢å¤: {avg['error_recoveries']:.1f}")
            print()
        
        # ç­–ç•¥å‡†ç¡®ç‡
        if "strategy_accuracy" in summary:
            print(f"ç­–ç•¥é€‰æ‹©å‡†ç¡®ç‡: {summary['strategy_accuracy']:.1f}%")
            print()
        
        # éªŒè¯é€šè¿‡ç‡
        if "verification_rate" in summary:
            print(f"éƒ¨ç½²éªŒè¯é€šè¿‡ç‡: {summary['verification_rate']:.1f}%")
            print()
        
        print(f"{'='*60}\n")


"""çœŸå®éƒ¨ç½²æµ‹è¯•æ‰§è¡Œå™¨ - æ‰§è¡ŒçœŸå®éƒ¨ç½²æµ‹è¯•å¹¶æ”¶é›†æŒ‡æ ‡"""
import time
import json
import requests
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List

from auto_deployer.workflow import DeploymentWorkflow, DeploymentRequest, LocalDeploymentRequest
from auto_deployer.config import AppConfig
from .test_projects import TestProject
from .test_environment import TestEnvironment

logger = logging.getLogger(__name__)


class DeploymentTester:
    """çœŸå®éƒ¨ç½²æµ‹è¯•æ‰§è¡Œå™¨"""
    
    def __init__(self, config: AppConfig, log_dir: Path = Path("tests/results")):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            config: Auto-Deployeråº”ç”¨é…ç½®
            log_dir: æ—¥å¿—å’Œç»“æœä¿å­˜ç›®å½•
        """
        self.config = config
        self.log_dir = Path(log_dir)
        self.workspace_dir = self.log_dir / "workspace"
        self.logs_dir = self.log_dir / "logs"
        
        # åˆ›å»ºç›®å½•
        self.workspace_dir.mkdir(parents=True, exist_ok=True)
        self.logs_dir.mkdir(parents=True, exist_ok=True)
    
    def test_project(
        self, 
        project: TestProject, 
        env_config: Dict[str, Any],
        timeout_minutes: int = 30,
        local_mode: bool = False
    ) -> Dict[str, Any]:
        """
        æµ‹è¯•å•ä¸ªé¡¹ç›®éƒ¨ç½²
        
        Args:
            project: æµ‹è¯•é¡¹ç›®é…ç½®
            env_config: ç¯å¢ƒé…ç½®ï¼ˆSSHè¿æ¥ä¿¡æ¯æˆ–æœ¬åœ°ç¯å¢ƒä¿¡æ¯ï¼‰
            timeout_minutes: è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            local_mode: æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å¼ï¼ˆTrue=æœ¬åœ°ï¼ŒFalse=SSHè¿œç¨‹ï¼‰
            
        Returns:
            åŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„å­—å…¸
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ§ª æµ‹è¯•é¡¹ç›®: {project.name}")
        logger.info(f"   ä»“åº“: {project.repo_url}")
        logger.info(f"   éš¾åº¦: {project.difficulty}")
        logger.info(f"   é¢„æœŸç­–ç•¥: {project.expected_strategy}")
        logger.info(f"   æµ‹è¯•æ¨¡å¼: {'ğŸ  æœ¬åœ°' if local_mode else 'ğŸ³ Dockerå®¹å™¨'}")
        logger.info(f"{'='*60}\n")
        
        start_time = time.time()
        
        # åˆ›å»ºéƒ¨ç½²å·¥ä½œæµ
        workflow = DeploymentWorkflow(
            config=self.config,
            workspace=str(self.workspace_dir)
        )
        
        try:
            # æ ¹æ®æ¨¡å¼åˆ›å»ºä¸åŒçš„éƒ¨ç½²è¯·æ±‚
            if local_mode:
                # æœ¬åœ°æ¨¡å¼
                request = LocalDeploymentRequest(
                    repo_url=project.repo_url,
                    deploy_dir=None  # ä½¿ç”¨é»˜è®¤ç›®å½•
                )
                logger.info("ğŸš€ å¼€å§‹æœ¬åœ°éƒ¨ç½²...")
                workflow.run_local_deploy(request)
            else:
                # SSH è¿œç¨‹æ¨¡å¼ï¼ˆDocker å®¹å™¨ï¼‰
                request = DeploymentRequest(
                    repo_url=project.repo_url,
                    host=env_config["host"],
                    port=env_config["port"],
                    username=env_config["username"],
                    auth_method="password",
                    password=env_config["password"],
                    key_path=None,
                    deploy_dir=None
                )
                logger.info("ğŸš€ å¼€å§‹è¿œç¨‹éƒ¨ç½²...")
                workflow.run_deploy(request)
            
            # ç­‰å¾…éƒ¨ç½²å®Œæˆï¼ˆAgentä¼šè‡ªå·±å®Œæˆï¼‰
            deployment_time = time.time() - start_time
            
            # æŸ¥æ‰¾æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
            log_file = self._find_latest_log(project.name)
            
            if not log_file:
                logger.warning("âš ï¸  æœªæ‰¾åˆ°éƒ¨ç½²æ—¥å¿—æ–‡ä»¶")
                return {
                    "project_name": project.name,
                    "project_difficulty": project.difficulty,
                    "success": False,
                    "error": "Log file not found",
                    "deployment_time_seconds": deployment_time
                }
            
            # è§£ææ—¥å¿—è·å–æŒ‡æ ‡
            metrics = self._extract_metrics(log_file, deployment_time, project)
            
            # éªŒè¯éƒ¨ç½²ç»“æœ
            logger.info("ğŸ” éªŒè¯éƒ¨ç½²ç»“æœ...")
            verification_result = self._verify_deployment(project, env_config)
            
            metrics.update({
                "verification_passed": verification_result["passed"],
                "verification_details": verification_result["details"]
            })
            
            # æœ€ç»ˆæˆåŠŸåˆ¤æ–­ï¼šéƒ¨ç½²æˆåŠŸä¸”éªŒè¯é€šè¿‡
            metrics["success"] = (
                metrics.get("success", False) and 
                verification_result["passed"]
            )
            
            logger.info(f"âœ… æµ‹è¯•å®Œæˆ: {'æˆåŠŸ' if metrics['success'] else 'å¤±è´¥'}")
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
            return {
                "project_name": project.name,
                "project_difficulty": project.difficulty,
                "success": False,
                "error": str(e),
                "deployment_time_seconds": time.time() - start_time
            }
    
    def _find_latest_log(self, project_name: str) -> Optional[Path]:
        """
        æŸ¥æ‰¾é¡¹ç›®çš„æœ€æ–°éƒ¨ç½²æ—¥å¿—
        
        Args:
            project_name: é¡¹ç›®åç§°
            
        Returns:
            æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        # æŸ¥æ‰¾agent_logsç›®å½•ï¼ˆAgenté»˜è®¤ä¿å­˜ä½ç½®ï¼‰
        agent_logs_dir = Path("agent_logs")
        if not agent_logs_dir.exists():
            # å°è¯•åœ¨logsç›®å½•æŸ¥æ‰¾
            agent_logs_dir = self.logs_dir
        
        # æŸ¥æ‰¾åŒ¹é…çš„æ—¥å¿—æ–‡ä»¶
        pattern = f"deploy_{project_name}_*.json"
        log_files = list(agent_logs_dir.glob(pattern))
        
        if not log_files:
            # å°è¯•æŸ¥æ‰¾æ‰€æœ‰æœ€è¿‘çš„æ—¥å¿—æ–‡ä»¶
            all_logs = list(agent_logs_dir.glob("deploy_*.json"))
            if all_logs:
                # è¿”å›æœ€æ–°çš„
                return max(all_logs, key=lambda p: p.stat().st_mtime)
            return None
        
        # è¿”å›æœ€æ–°çš„åŒ¹é…æ–‡ä»¶
        return max(log_files, key=lambda p: p.stat().st_mtime)
    
    def _extract_metrics(
        self, 
        log_file: Path, 
        deployment_time: float, 
        project: TestProject
    ) -> Dict[str, Any]:
        """
        ä»æ—¥å¿—æ–‡ä»¶ä¸­æå–æŒ‡æ ‡
        
        Args:
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            deployment_time: éƒ¨ç½²è€—æ—¶ï¼ˆç§’ï¼‰
            project: æµ‹è¯•é¡¹ç›®é…ç½®
            
        Returns:
            æŒ‡æ ‡å­—å…¸
        """
        try:
            with open(log_file, "r", encoding="utf-8") as f:
                log = json.load(f)
        except Exception as e:
            logger.error(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"Failed to read log: {e}",
                "deployment_time_seconds": deployment_time
            }
        
        # æå–æ­¥éª¤ä¿¡æ¯
        steps = log.get("steps", [])
        
        # è®¡ç®—å„ç§æŒ‡æ ‡
        total_iterations = len(steps)
        total_commands = 0
        user_interactions = 0
        error_recovery_count = 0
        
        for step in steps:
            # è®¡ç®—å‘½ä»¤æ•°
            if isinstance(step.get("result"), dict):
                commands = step.get("result", {}).get("commands", [])
                if isinstance(commands, list):
                    total_commands += len(commands)
                else:
                    total_commands += 1
            else:
                total_commands += 1
            
            # ç»Ÿè®¡ç”¨æˆ·äº¤äº’
            if step.get("action") == "ask_user":
                user_interactions += 1
            
            # ç»Ÿè®¡é”™è¯¯æ¢å¤
            if isinstance(step.get("result"), dict):
                if not step.get("result", {}).get("success", True):
                    error_recovery_count += 1
        
        # æå–ç­–ç•¥ä¿¡æ¯
        plan = log.get("plan", {})
        strategy_used = plan.get("strategy") if plan else None
        if not strategy_used:
            # å°è¯•ä»æ—¥å¿—ä¸­æ¨æ–­ç­–ç•¥
            commands_str = str(log).lower()
            if "docker-compose" in commands_str:
                strategy_used = "docker-compose"
            elif "docker" in commands_str:
                strategy_used = "docker"
            else:
                strategy_used = "traditional"
        
        strategy_correct = (
            strategy_used == project.expected_strategy
            if strategy_used and project.expected_strategy
            else None
        )
        
        # æ„å»ºæŒ‡æ ‡å­—å…¸
        metrics = {
            "project_name": project.name,
            "project_difficulty": project.difficulty,
            "success": log.get("status") == "success",
            "final_status": log.get("status", "unknown"),
            "deployment_time_seconds": deployment_time,
            
            # æ•ˆç‡æŒ‡æ ‡
            "total_iterations": total_iterations,
            "total_commands": total_commands,
            
            # LLMç›¸å…³
            "llm_call_count": total_iterations,  # æ¯æ¬¡è¿­ä»£ä¸€æ¬¡LLMè°ƒç”¨
            
            # è´¨é‡æŒ‡æ ‡
            "user_interactions": user_interactions,
            "error_recovery_count": error_recovery_count,
            
            # ç­–ç•¥é€‰æ‹©
            "strategy_used": strategy_used,
            "expected_strategy": project.expected_strategy,
            "strategy_correct": strategy_correct,
            
            # æ—¥å¿—æ–‡ä»¶
            "log_file": str(log_file),
        }
        
        return metrics
    
    def _verify_deployment(
        self, 
        project: TestProject, 
        env_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        éªŒè¯éƒ¨ç½²ç»“æœ
        
        Args:
            project: æµ‹è¯•é¡¹ç›®é…ç½®
            env_config: ç¯å¢ƒé…ç½®
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        verification = project.verification
        urls = verification.urls
        
        if not urls:
            return {
                "passed": True,
                "details": [{"message": "No verification URLs defined"}]
            }
        
        results = []
        all_passed = True
        
        for url in urls:
            try:
                # å‘é€HTTPè¯·æ±‚
                response = requests.get(
                    url,
                    timeout=verification.timeout,
                    allow_redirects=True
                )
                
                expected_status = verification.expected_status
                status_match = response.status_code == expected_status
                
                # æ£€æŸ¥å†…å®¹ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
                content_match = True
                if verification.expected_content:
                    content_match = verification.expected_content in response.text
                
                passed = status_match and content_match
                all_passed = all_passed and passed
                
                results.append({
                    "url": url,
                    "status_code": response.status_code,
                    "expected_status": expected_status,
                    "status_match": status_match,
                    "content_match": content_match,
                    "passed": passed,
                    "response_length": len(response.text)
                })
                
                logger.info(
                    f"   {url}: {response.status_code} "
                    f"({'âœ…' if passed else 'âŒ'})"
                )
                
            except requests.exceptions.Timeout:
                results.append({
                    "url": url,
                    "error": "Timeout",
                    "passed": False
                })
                all_passed = False
                logger.warning(f"   {url}: è¶…æ—¶")
                
            except requests.exceptions.ConnectionError:
                results.append({
                    "url": url,
                    "error": "Connection refused",
                    "passed": False
                })
                all_passed = False
                logger.warning(f"   {url}: è¿æ¥è¢«æ‹’ç»")
                
            except Exception as e:
                results.append({
                    "url": url,
                    "error": str(e),
                    "passed": False
                })
                all_passed = False
                logger.warning(f"   {url}: é”™è¯¯ - {e}")
        
        return {
            "passed": all_passed,
            "details": results
        }

